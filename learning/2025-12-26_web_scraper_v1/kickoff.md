---
type: daily_kickoff
date: 2025-12-26
day: 8/14
topic: Web Scraper v1 â€” Setup & Foundation
duration: 8 hours
status: ğŸ”´ ACTIVE
---

# ğŸ”´ DAN 8 KICKOFF â€” Web Scraper v1: Setup & Foundation

**Dobar dan, Jole! ğŸ‘‹**

Sada poÄinjĞµÅ¡ sa najzanimljivijim delom â€” **Web Scraper projektom!**

---

## ğŸ“Š Vremenska Raspodela Dana (8h)

```
09:00 â€” Kickoff + Setup (15 min)
09:15 â€” FAZA 1: Requests + BeautifulSoup (1.5h)
         â”œâ”€ Instalacija
         â”œâ”€ GET zahteve
         â”œâ”€ HTML parsing
         â””â”€ REPL praksa
10:45 â€” Pauza (15 min)

11:00 â€” FAZA 2: Project Setup (1.5h)
         â”œâ”€ Struktura direktorijuma
         â”œâ”€ config.py
         â”œâ”€ requirements.txt
         â””â”€ Git setup

12:30 â€” RuÄak (30 min)

13:00 â€” FAZA 3: Scraper Core (2h)
         â”œâ”€ scraper.py osnova
         â”œâ”€ fetch_page(url)
         â”œâ”€ Headers + timeout
         â””â”€ Error handling

15:00 â€” Pauza (15 min)

15:15 â€” FAZA 4: Testing Setup (2h)
         â”œâ”€ conftest.py fixtures
         â”œâ”€ test_scraper_basics.py
         â”œâ”€ Mock testovi
         â””â”€ Coverage check

17:15 â€” Finalizacija (15 min)
         â”œâ”€ Rekapitulacija
         â”œâ”€ Checklist
         â””â”€ Git commit

17:30 â€” DAN 8 DONE âœ…
```

---

## ğŸ¯ Tri Linije Dana

### Linija 1ï¸âƒ£ â€” "Å½elim da razumem Å¡ta se deÅ¡ava"

ğŸ‘‰ **Za tebe:**

-   ÄŒitaj README.md (Overview)
-   ÄŒitaj cheatsheet.md (Requests + BeautifulSoup osnove)
-   Prati web_scraper_setup_guide.md **korak po korak**
-   Radi REPL primere
-   PiÅ¡i testove

---

### Linija 2ï¸âƒ£ â€” "Samo mi reÅ¡i zadatak"

ğŸ‘‰ **Za tebe:**

-   PreskoÄi teoriju
-   Idi direktno na web_scraper_setup_guide.md
-   IspratĞ¸ sve korake
-   Uradi testove
-   Komit

---

### Linija 3ï¸âƒ£ â€” "Imam iskustvo, samo mi reÄi Å¡ta trebam"

ğŸ‘‰ **Za tebe:**

-   Koristi tasks.md kao checklist
-   Pogledaj cheatsheet.md za reference
-   PiÅ¡i code prema specifikaciji
-   Testiraj

---

## ğŸ—ï¸ Tri Filara Dana 8

### Pilar 1: Instalacija + Osnove (1.5h)

**Å ta uÄiÅ¡:**

```python
import requests
response = requests.get("https://example.com")
print(response.status_code)  # 200

from bs4 import BeautifulSoup
soup = BeautifulSoup(response.text, "html.parser")
titles = soup.select("h1")
```

**Rezultat:** MoÅ¾eÅ¡ da:

-   âœ… NapraviÅ¡ GET zahtev
-   âœ… ProveiraÅ¡ status kod
-   âœ… ParsiraÅ¡ HTML sa CSS selektorima
-   âœ… EkstraktujeÅ¡ tekst iz HTML-a

---

### Pilar 2: Struktura Projekta (1.5h)

**Å ta kreirĞ°Å¡:**

```
projects/01-web-scraper/
â”œâ”€â”€ config.py          # Settings (URL, headers, timeout)
â”œâ”€â”€ scraper.py         # Main logika
â”œâ”€â”€ requirements.txt   # pip freeze
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py    # Fixtures
â”‚   â””â”€â”€ test_scraper_basics.py
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ app.log
â”œâ”€â”€ output/
â”‚   â””â”€â”€ sample.csv
â””â”€â”€ README.md
```

**Rezultat:** Struktura je profesionalna i skalabilna.

---

### Pilar 3: Scraper Core + Tests (3.5h)

**Å ta kreirĞ°Å¡:**

```python
# scraper.py
def fetch_page(url: str, timeout: int = 5) -> str:
    """Fetch HTML sa error handling."""

# tests/test_scraper_basics.py
def test_fetch_page_with_valid_url(mock_response):
    """Test fetch_page sa mock-om."""
```

**Rezultat:**

-   âœ… Scraper je testabilan
-   âœ… Svaka funkcija ima test
-   âœ… Coverage >70%

---

## ğŸ“ Kako KoristiÅ¡ Materijal Danas?

### âœ… Jednostavna Formula

```
1. Otvori web_scraper_setup_guide.md
2. Prati FAZU 1, 2, 3, 4 redom
3. Svaki primer radi u REPL-u
4. Ako ne razumeÅ¡ neÅ¡to:
   â†’ ÄŒitaj relevant sekciju iz cheatsheet.md
5. Posle svake faze:
   â†’ Proveri tasks.md checklist
6. Na kraju:
   â†’ Git commit "Day 8: Web Scraper Setup"
```

---

## ğŸš¨ ÄŒeste GreÅ¡ke (Izbegni!)

### âŒ LOÅ E: Preskakanje instalacije

```bash
# LOÅ E
python3 -c "import requests"  # Verovatno Ä‡e pucati

# DOBRO
source venv/bin/activate
pip install requests beautifulsoup4
```

---

### âŒ LOÅ E: Ne kreiraj config.py

```python
# LOÅ E: URL-ovi hardkodirani
def scrape():
    r = requests.get("https://example.com/page")

# DOBRO: config.py
CONFIG = {"BASE_URL": "https://example.com"}
def scrape():
    r = requests.get(CONFIG["BASE_URL"] + "/page")
```

---

### âŒ LOÅ E: Ne testiraj

```python
# LOÅ E: Nema testova
# DOBRO
def test_fetch_page_returns_string():
    result = fetch_page("https://httpbin.org/html")
    assert isinstance(result, str)
```

---

### âŒ LOÅ E: Nema error handling-a

```python
# LOÅ E: Ako server ne odgovara?
response = requests.get(url)
soup = BeautifulSoup(response.text)

# DOBRO: Handluj greÅ¡ke
try:
    response = requests.get(url, timeout=5)
    response.raise_for_status()
except requests.RequestException as e:
    logger.error(f"Failed: {e}")
    raise
```

---

## ğŸ’ª Motivacija

Primetio sam da si brz sa uÄenjem. Dan 5 (Type Annotations) je bio teÅ¡ko, ali si ga proslavio! Isti pristup koristi za Dan 8:

1. **ProÄitaj** sve pre nego poÄneÅ¡
2. **PraktisuĞ¹** u REPL-u
3. **PiÅ¡i testove** od poÄetka
4. **KomituĞ¹** na kraju

**Rezultat?** Profesionalni Web Scraper koji moÅ¾eÅ¡ da pokazujeÅ¡ poslodavcima! ğŸ‰

---

## ğŸ¯ Å ta je Uspeh Za Dan 8?

Ako na kraju dana **OVO SVE** moÅ¾eÅ¡ da uradi:

```python
# 1. Instalacija
source venv/bin/activate
python3

# 2. Requests
>>> import requests
>>> r = requests.get("https://httpbin.org/html")
>>> print(r.status_code)
200

# 3. BeautifulSoup
>>> from bs4 import BeautifulSoup
>>> soup = BeautifulSoup(r.text, "html.parser")
>>> print(len(soup.select("p")))
42

# 4. Scraper
>>> from scraper import fetch_page
>>> html = fetch_page("https://httpbin.org/html")
>>> print(len(html) > 0)
True

# 5. Testovi
$ pytest tests/ -v
tests/test_scraper_basics.py::test_fetch_page_returns_string PASSED
tests/test_scraper_basics.py::test_fetch_page_handles_error PASSED
...
4 passed in 0.23s
```

---

## ğŸš€ Ako Brzo ZavrÅ¡iÅ¡?

Dodatne aktivnosti:

1. **Eksperimenti sa CSS selektorima** â€” try `soup.select()` na razliÄitim URL-ovima
2. **Dodaj retry logiku** â€” pokuÅ¡aj zahtev 3x pre nego odustaneÅ¡
3. **Testiraj sa user-agent stringu** â€” vidi kako serveri reaguju
4. **Kreiraj conftest.py mock fixture** â€” practice za Dan 9

---

## ğŸ“ Ako Zaglavim DuÅ¾e od 15 Minuta?

### 1ï¸âƒ£ Proveri cheatsheet.md

Verovatan odgovor je tamo. Primer:

-   "Kako da proverim status kod?" â†’ cheatsheet.md sekcija "Status Codes"

### 2ï¸âƒ£ Pogledaj chatlog.md

ÄŒeste greÅ¡ke su veÄ‡ tu.

### 3ï¸âƒ£ Pitaj AI sa greÅ¡kom

Kopi-paÑÑ‚Ğ° greÅ¡ku + kod â†’ dobiÄ‡eÅ¡ odgovor u 30 sekundi

---

## â° Vremenske Preporuke Po Fazi

| Faza         | Vreme | Aktivnost      | Rezultat           |
| ------------ | ----- | -------------- | ------------------ |
| 1            | 1.5h  | Requests + BS4 | Znam osnove        |
| 2            | 1.5h  | Project setup  | Struktura je jasna |
| 3            | 2h    | Scraper core   | fetch_page() radi  |
| 4            | 2h    | Testing        | 4+ testova prolaze |
| Finalizacija | 15min | Git + review   | Spreman za Dan 9   |

---

## âœ… Pre Nego PoÄneÅ¡ â€” Provera Stanja

Ponovi od mene: "ZavrÅ¡io sam Dan 6-7 (Pathlib + Testing) i razumem:"

-   [ ] `Path` operacije
-   [ ] Pytest fixtures (`tmp_path`)
-   [ ] Error handling (`try/except`)
-   [ ] `logging` modul
-   [ ] TypedDict za podatke
-   [ ] Type hints sa `->` return type

Ako je sve âœ… â†’ **Spreman si! ğŸš€**

---

## ğŸ“– Redosled Materijala Danas

1. âœ… **Sada:** Ovo (kickoff.md) â€” 5 min
2. â†’ **SledeÄ‡e:** [cheatsheet.md](./cheatsheet.md) â€” 30 min
3. â†’ **GLAVNO:** [web_scraper_setup_guide.md](./web_scraper_setup_guide.md) â€” 6h (prati sve FAZE)
4. â†’ **Reference:** [tasks.md](./tasks.md) â€” tokom dana
5. â†’ **Q&A:** [chatlog.md](./chatlog.md) â€” ako zaglavim

---

## ğŸ‰ Finalna Poruka

> "Today you start building something real. By the end of the day, you'll have a professional Web Scraper project structure with tests, logging, and proper error handling. Same discipline as Day 5 (Type Annotations), same results. Let's go! ğŸ’ª"

---

**Na putu! ğŸš€**

**SledeÄ‡a stvar:** Otvori [cheatsheet.md](./cheatsheet.md) i poÄni sa Requests osnove.

---
